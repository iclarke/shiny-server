Vehicle_make[i] <- car_make
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,Error_code_list))
All_error_texts
library(DT)
install.packages("DT")
library(DT)
a <- c("Audi","bb")
b <- c("Audi","cc")
length(intersect(a,b))
# The goal here is to run through all the folders and subfolders, read each PDF, extract the key features, and store into a data frame
File_Name <- character()
Vehicle_make <- character()
Error_code_list <- list()
Error_text_list <-  list()
All_error_codes <- character()
All_error_texts <- character()
# Feature extraction
i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep(".....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, ".....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c)))
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,Error_code_list,Error_text_list))
a <- character()
length(a)
a[1] <- "w"
length(a)
library(stringr)
library(stringr)
out_text <- extract_text("./Inputs/PDF/ Diagnostic Report sn09nxv.pdf")
library(tabulizer)
library(stringr)
library(gsubfn)
car_makes <- c("ACURA","AM GENERAL","AMERICAN IRONHORSE","APRILIA","ARCTIC CAT","ASTON MARTIN","ATK","AUDI","AVANTI","BENTLEY","BIG DOG","BIMOTA","BLUE BIRD","BMW","BOMBARDIER","BUELL","BUICK","CADILLAC","CANNONDALE","CHANCE COACH TRANSIT BUS","CHEVROLET","CHRYSLER","COBRA","DAEWOO","DODGE","DUCATI","E-TON","EL DORADO","FERRARI","FORD","FREIGHTLINER","GAS GAS","GILLIG","GMC","HARLEY DAVIDSON","HINO","HM","HONDA","HUSABERG","HUSQVARNA","HYUNDAI","INDIAN","INFINITI","INTERNATIONAL","ISUZU","JAGUAR","JEEP","KAWASAKI","KENWORTH","KIA","KTM","KYMCO","LAFORZA","LAMBORGHINI","LANDROVER","LEXUS","LINCOLN","LOTUS","MACK","MAZDA","MERCEDES-BENZ","MERCURY","MITSUBISHI","MITSUBISHI FUSO","MOTO GUZZI","MOTOR COACH INDUSTRIES","MV AGUSTA","NEW FLYER","NISSAN","NOVA BUS CORPORATION","OLDSMOBILE","ORION BUS","OSHKOSH MOTOR TRUCK CO.","OTTAWA","PANOZ","PETERBILT","PEUGEOT","PLYMOUTH","POLARIS","PONTIAC","PORSCHE","QVALE","RENAULT","ROLLS ROYCE","SAAB","SATURN","SEA-DOO","SEAT","SKI-DOO","STERLING","STERLING TRUCK","SUBARU","SUZUKI","TM","TOYOTA","TRIUMPH","UD","VICTORY","VOLKSWAGEN","VOLVO","WESTERN STAR","WORKHORSE","YAMAHA","ALFA ROMEO","AUTOCAR LLC.","COUNTRY COACH MOTORHOME","HUMMER","KASEA","LEM","MASERATI","MINI","MORGAN","SALEEN","WESTERN RV","MAYBACH","ROVER","VENTO","FIAT","JOHN DEERE","KUBOTA","SCION","SMART","VESPA","HYOSUNG","PIAGGIO","ARGO","BUGATTI","PIERCE MFG. INC.","AMERICAN LAFRANCE","CAN-AM","CRANE CARRIER","CUB CADET","BETA","BOBCAT","TESLA","RAM","VPG","CODA","FISKER","MCLAREN","SRT","BERTONE","IC CORPORATION","NASH")
out_text <- extract_text("./Inputs/PDF/ Diagnostic Report sn09nxv.pdf")
out_text
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
out_text_words
error_codes <- as.vector(unique (grep(".....\\-\\d\\d", out_text_words, value=TRUE)))
error_codes
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
error_codes
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c)))
error_texts
error_texts <- error_texts[nchar(error_texts)>2]
error_texts
out_text
VIN_number <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c)))
VIN_number
out_text
VIN_number <- VIN_number[nchar(VIN_number)>2]
VIN_number
#install.packages("RPostgreSQL")
require("RPostgreSQL")
library(jsonlite)
library(dplyr)
library(ggplot2)
library(highcharter)
library(geojsonio)
library(lubridate)
library(tabulizer)
library(stringr)
library(gsubfn)
out_text
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
test_time_text
View(features_df)
i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number[nchar(VIN_number)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- VIN_number_text
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
File_Name <- character()
Vehicle_make <- character()
Error_code_list <- list()
Error_text_list <-  list()
All_error_codes <- character()
All_error_texts <- character()
VIN_number <- character()
Test_time <- .POSIXct(character())
i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number[nchar(VIN_number)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- VIN_number_text
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
View(features_df)
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number[nchar(VIN_number)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- VIN_number_text
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
VIN_number
VIN_number
VIN_number <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c)))
VIN_number <- VIN_number[nchar(VIN_number)>2]
VIN_number
VIN_number <- character()
i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number[nchar(VIN_number)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- VIN_number_text
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
VIN_number
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- VIN_number_text
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
VIN_number
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
VIN_number
View(features_df)
dim(Vehicle_make)
length(Vehicle_make)
length(File_Name)
length(VIN_number)
length(Test_time)
out_text
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\n).*", simplify = c)))
test_time_text
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
length(Error_text_list)
length(Error_code_list)
Error_text_list
length(VIN_number)
length(File_Name)
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
test_time_text
Test_time
length(Test_time)
Test_time_final <- as.POSIXct(rep(NA,length(Test_time)))
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time_final,Error_code_list,Error_text_list))
View(features_df)
for (i in 1:length(Test_time)){
Test_time_final[i] <- Test_time[i]
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time_final,Error_code_list,Error_text_list))
View(features_df)
Test_time_final <- as.POSIXct(rep(NA,length(Test_time)))
for (i in 1:length(Test_time)){
Test_time_final[i] <- Test_time[i]
}
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time_final,Error_code_list,Error_text_list))
Test_time
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
str(features_df)
features_df <- as.data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
class(features_df$Test_time)
class(features_df)
type(features_df$Test_time)
class(features_df$Test_time)
Test_time_final <- as.POSIXct(rep(NA,length(Test_time)))
Test_time_final
for (i in 1:length(Test_time)){
Test_time_final[i] <- Test_time[i]
}
Test_time_final
Test_time[10]
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list)
View(features_df)
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list))
features_df <- data.frame(File_Name,Vehicle_make,VIN_number,Test_time,Error_code_list,Error_text_list)
features_df <- data.frame(cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list),Test_time)
View(features_df)
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
View(features_df)
features_df <- data.frame(features_df,Test_time)
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
features_df <- data.frame(features_df,Test_time)
View(myDf)
nrow(features_df)
length(Test_time)
length(File_Name)
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
All_error_codes
Error_code_list
Error_code_list <- list()
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
Error_code_list
File_Name <- character()
Vehicle_make <- character()
Error_code_list <- list()
Error_text_list <-  list()
All_error_codes <- character()
All_error_texts <- character()
VIN_number <- character()
i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
#Extract text from PDF
out_text <- extract_text(file_name)
#Basic text cleansing to enmable text recognition
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)
#Extract feature from cleansed text
error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
error_texts <- ifelse(length(error_texts)==0,"NA",error_texts)
error_codes <- ifelse(length(error_codes)==0,"NA",error_texts)
error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
File_Name[i] <- file_name
Vehicle_make[i] <- car_make
VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
Test_time[i] <- test_time_text
Error_code_list[[length(Error_code_list)+1]] <- error_codes
Error_text_list[[length(Error_text_list)+1]] <- error_texts
All_error_codes <- c(All_error_codes,error_codes)
All_error_texts <- c(All_error_texts,error_texts)
i <- i+1
}
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
features_df <- data.frame(features_df,Test_time)  # Problem here as vector of lists seem to have bigger length.
Error_code_list
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
View(features_df)
features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
features_df <- as.data.frame(features_df)
