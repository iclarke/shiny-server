---
title: "Autel EDA"
author: "Samy"
date: "13 September 2017"
output: html_document
---

```{r setup, include=FALSE}

  #install.packages("RPostgreSQL")
  require("RPostgreSQL")

 
  library(jsonlite)
  library(dplyr)
  library(ggplot2)
  library(highcharter)
  library(geojsonio)
  library(lubridate)
  library(tabulizer)
  library(stringr)
  library(gsubfn)
  

```

```{r Load JSON data fro Redshift}

  #Initialise connection
  drv <- dbDriver("PostgreSQL")
  con <-dbConnect(drv,dbname="dev",host="redjson.cih6vs0jk7a3.eu-west-1.redshift.amazonaws.com",port=5439,
                user="redjsonuser",password="Redjsonpass1")
  
  
  #Get list of all available tables
  
  red_table_list <- dbGetQuery(con, "select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';") %>% 
    mutate(prefix = substr(relname,1,3))
   # filter(prefix %in% c("red"))
  head(red_table_list)
  
  #Query one specific table
  table_ex <-  dbGetQuery(conn = con,statement = "SELECT * FROM stl_s3client")
  str(table_ex)
  
  dbDisconnect(con)




```

```{r Extract data from PDF}

#Installing tabula R bindings 

install.packages("ghit",repos='http://cran.us.r-project.org') 
library(ghit)
#ghit::install_github(c("leeper/tabulizerjars", "leeper/tabulizer"), INSTALL_opts = "--no-multiarch", dependencies = c("Depends", "Imports"))
ghit::install_github(c("leeper/tabulizerjars", "leeper/tabulizer"), INSTALL_opts = "--no-multiarch", dependencies = c("Depends", "Imports"))
install.packages("gsubfn")

library(tabulizer)
library(stringr)
library(gsubfn)

#List of all car makes

car_makes <- c("ACURA","AM GENERAL","AMERICAN IRONHORSE","APRILIA","ARCTIC CAT","ASTON MARTIN","ATK","AUDI","AVANTI","BENTLEY","BIG DOG","BIMOTA","BLUE BIRD","BMW","BOMBARDIER","BUELL","BUICK","CADILLAC","CANNONDALE","CHANCE COACH TRANSIT BUS","CHEVROLET","CHRYSLER","COBRA","DAEWOO","DODGE","DUCATI","E-TON","EL DORADO","FERRARI","FORD","FREIGHTLINER","GAS GAS","GILLIG","GMC","HARLEY DAVIDSON","HINO","HM","HONDA","HUSABERG","HUSQVARNA","HYUNDAI","INDIAN","INFINITI","INTERNATIONAL","ISUZU","JAGUAR","JEEP","KAWASAKI","KENWORTH","KIA","KTM","KYMCO","LAFORZA","LAMBORGHINI","LANDROVER","LEXUS","LINCOLN","LOTUS","MACK","MAZDA","MERCEDES-BENZ","MERCURY","MITSUBISHI","MITSUBISHI FUSO","MOTO GUZZI","MOTOR COACH INDUSTRIES","MV AGUSTA","NEW FLYER","NISSAN","NOVA BUS CORPORATION","OLDSMOBILE","ORION BUS","OSHKOSH MOTOR TRUCK CO.","OTTAWA","PANOZ","PETERBILT","PEUGEOT","PLYMOUTH","POLARIS","PONTIAC","PORSCHE","QVALE","RENAULT","ROLLS ROYCE","SAAB","SATURN","SEA-DOO","SEAT","SKI-DOO","STERLING","STERLING TRUCK","SUBARU","SUZUKI","TM","TOYOTA","TRIUMPH","UD","VICTORY","VOLKSWAGEN","VOLVO","WESTERN STAR","WORKHORSE","YAMAHA","ALFA ROMEO","AUTOCAR LLC.","COUNTRY COACH MOTORHOME","HUMMER","KASEA","LEM","MASERATI","MINI","MORGAN","SALEEN","WESTERN RV","MAYBACH","ROVER","VENTO","FIAT","JOHN DEERE","KUBOTA","SCION","SMART","VESPA","HYOSUNG","PIAGGIO","ARGO","BUGATTI","PIERCE MFG. INC.","AMERICAN LAFRANCE","CAN-AM","CRANE CARRIER","CUB CADET","BETA","BOBCAT","TESLA","RAM","VPG","CODA","FISKER","MCLAREN","SRT","BERTONE","IC CORPORATION","NASH")


# Extracting text and individual words from PDF
out_text <- extract_text("./Inputs/PDF/ Diagnostic Report sn09nxv.pdf")
out_text <- gsub("\\","", out_text,fixed=TRUE)
out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
out_text_words <- gsub("\r","",out_text_words)
out_text_words <- gsub("\n","",out_text_words)

#Find matches corresponding to error codes & car make


error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
car_make <- intersect(out_text_words,car_makes)
#error_textx <- gsub(".*.....\\-\\d\\d | (\r\n|\r|\n).*","",out_text)
error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c)))
VIN_number <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c)))
VIN_number <- VIN_number[nchar(VIN_number)>2]

test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\n).*", simplify = c)))
test_time_text <- test_time_text[nchar(test_time_text) >2]
test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")
test_time_text
summary_data <- c("YK64 XVX.pdf",list(error_codes),list(error_texts),car_make)

#Testing which files are bieng listed and searched
dir(path = "./Inputs/PDF/",pattern = NULL,full.names=TRUE,recursive=TRUE)

#Testing regex etc
error_texts <- error_texts[nchar(error_texts)>2]
error_texts
out_text
VIN_number
test_time_text


```

```{r Loop through folders and create a table with key features}
# The goal here is to run through all the folders and subfolders, read each PDF, extract the key features, and store into a data frame


File_Name <- character()
Vehicle_make <- character()
Error_code_list <- list()
Error_text_list <-  list()


# Feature extraction

i=1
for (file_name in dir(path = "./Inputs/PDF/",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)){
  

  
  #Extract text from PDF
  out_text <- extract_text(file_name)
  #Basic text cleansing to enmable text recognition
  out_text <- gsub("\\","", out_text,fixed=TRUE)
  out_text_words <- unique(strsplit(paste(out_text, collapse = " "), ' ')[[1]])
  out_text_words <- gsub("\r","",out_text_words)
  out_text_words <- gsub("\n","",out_text_words)
  
  #Extract feature from cleansed text

  error_codes <- as.vector(unique (grep("[A-Z]....\\-\\d\\d", out_text_words, value=TRUE)))
  car_make <- ifelse(length(intersect(out_text_words,car_makes)) == 0,"Not found",intersect(out_text_words,car_makes)) # to avoid zero length error
  error_texts <- as.vector(unique(strapplyc(out_text, "[A-Z]....\\-\\d\\d(.*?)(\r\n|\r|\n).*", simplify = c))) # Assumes 1st char error code is letter
  error_texts <- ifelse(length(error_texts)==0,"NA",error_texts)
  error_codes <- ifelse(length(error_codes)==0,"NA",error_codes)
  
  error_texts <- error_texts[nchar(error_texts)>2] #Retaining only elements with at least 3 characters
  VIN_number_text <- as.vector(unique(strapplyc(out_text, "VIN:(.*?)(\r\n|\r|\n).*", simplify = c))) # Regex would need improving to avoid next line
  VIN_number_text <- VIN_number_text[nchar(VIN_number_text)>2]
  
  
  test_time_text <- as.vector(unique(strapplyc(out_text, "Test Time: (.*?)(\r\n|\r|\n).*", simplify = c)))
  test_time_text <- test_time_text[nchar(test_time_text) >2]
  test_time_text <- as.POSIXct(test_time_text,format = "%Y-%M-%M %H:%M:%S")


  
  
  
  File_Name[i] <- file_name
  Vehicle_make[i] <- car_make
  VIN_number[i] <- ifelse(length(VIN_number_text) == 0,"NA",VIN_number_text)
  Test_time[i] <- test_time_text
  
  Error_code_list[[length(Error_code_list)+1]] <- error_codes
  Error_text_list[[length(Error_text_list)+1]] <- error_texts
  All_error_codes <- c(All_error_codes,error_codes)
  All_error_texts <- c(All_error_texts,error_texts)
  
  
  i <- i+1
  
}

features_df <- cbind(File_Name,Vehicle_make,VIN_number,Error_code_list,Error_text_list)
features_df <- as.data.frame(features_df)
features_df <- data.frame(features_df,Test_time)  # Problem here as vector of lists seem to have bigger length.



```

```{r debug}

debug_list <- character()

i=1
for (file_name in dir(path = "./Inputs/PDF/858500 - Russell Emptage/",pattern = "*diagnostic*\\.pdf$",full.names=TRUE,recursive=TRUE)){
  
  debug_list[i] <- file_name
  
  i <- i+1
  
}
debug_list

list.files(path = "./",pattern = "^.*Diagnostic.*\\.pdf",full.names=TRUE,recursive=TRUE)

```

